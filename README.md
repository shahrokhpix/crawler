# Fars News Crawler ğŸ•·ï¸

A powerful, production-ready web crawler for Fars News website built with Node.js, Puppeteer, and PostgreSQL. Now with full Docker support for easy deployment on Ubuntu servers.

[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://www.docker.com/)
[![Node.js](https://img.shields.io/badge/Node.js-18+-green.svg)](https://nodejs.org/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15+-blue.svg)](https://www.postgresql.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

Ø³ÛŒØ³ØªÙ… Ø®Ø¨Ø±Ø®ÙˆØ§Ù† Ø®ÙˆØ¯Ú©Ø§Ø± ÙØ§Ø±Ø³ Ù†ÛŒÙˆØ² Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØª Ú©Ø±Ø§Ù„ Ú†Ù†Ø¯Ù…Ù†Ø¨Ø¹Ù‡ Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù…Ø­ØªÙˆØ§

## ğŸš€ Quick Start (Docker)

### One-Command Installation

```bash
curl -fsSL https://raw.githubusercontent.com/shahrokhpix/crawler/main/quick-start.sh | bash
```

### Manual Docker Installation

```bash
# Clone repository
git clone https://github.com/shahrokhpix/crawler.git
cd crawler

# Copy environment file
cp .env.docker .env

# Start with Docker Compose
docker compose -f docker-compose.simple.yml up -d

# Access admin panel
open http://localhost:3004/admin
```

**Default credentials**: admin / admin123 (change in production)

## ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ

- ğŸš€ **Ú©Ø±Ø§Ù„ Ú†Ù†Ø¯Ù…Ù†Ø¨Ø¹Ù‡**: Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ Ø®Ø¨Ø±ÛŒ Ù…ØªØ¹Ø¯Ø¯
- ğŸ”„ **Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø±**: Ú©Ø±Ø§Ù„ Ø¯ÙˆØ±Ù‡â€ŒØ§ÛŒ Ø¨Ø§ cron jobs
- ğŸ¯ **ØªØ´Ø®ÛŒØµ ØªÚ©Ø±Ø§Ø±ÛŒ**: Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø°Ø®ÛŒØ±Ù‡ Ù…Ù‚Ø§Ù„Ø§Øª ØªÚ©Ø±Ø§Ø±ÛŒ
- ğŸ“Š **Ù¾Ù†Ù„ Ù…Ø¯ÛŒØ±ÛŒØª**: Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ ÙˆØ¨ Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª
- ğŸ³ **Docker Ready**: Ù†ØµØ¨ Ø¢Ø³Ø§Ù† Ø¨Ø§ Docker
- ğŸ“ˆ **Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯**: Ù†Ø¸Ø§Ø±Øª Ø¨Ø± Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø³ÛŒØ³ØªÙ…
- ğŸ”’ **Ø§Ù…Ù†ÛŒØª**: Ø§Ø­Ø±Ø§Ø² Ù‡ÙˆÛŒØª Ùˆ Ú©Ù†ØªØ±Ù„ Ø¯Ø³ØªØ±Ø³ÛŒ
- ğŸ“Š **Production Monitoring**: Prometheus and Grafana integration
- ğŸ”„ **Load Balancing**: Multiple app instances with Nginx

## Ù†ØµØ¨ Ø³Ø±ÛŒØ¹ Ø¨Ø§ Docker

### Ù¾ÛŒØ´â€ŒÙ†ÛŒØ§Ø²Ù‡Ø§

- Docker Engine 20.10+
- Docker Compose 2.0+
- Ø­Ø¯Ø§Ù‚Ù„ 2GB RAM
- Ø­Ø¯Ø§Ù‚Ù„ 5GB ÙØ¶Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ

### Ù†ØµØ¨ Docker Ø±ÙˆÛŒ Ubuntu

```bash
# Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø³ÛŒØ³ØªÙ…
sudo apt update && sudo apt upgrade -y

# Ù†ØµØ¨ Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# Ø§ÙØ²ÙˆØ¯Ù† Ú©Ø§Ø±Ø¨Ø± Ø¨Ù‡ Ú¯Ø±ÙˆÙ‡ docker
sudo usermod -aG docker $USER

# Ù†ØµØ¨ Docker Compose
sudo apt install docker-compose-plugin -y

# Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Docker
sudo systemctl enable docker
sudo systemctl start docker
```

### Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡

```bash
# Ú©Ù„ÙˆÙ† Ù¾Ø±ÙˆÚ˜Ù‡
git clone https://github.com/shahrokhpix/crawler.git
cd crawler

# Ú©Ù¾ÛŒ ÙØ§ÛŒÙ„ ØªÙ†Ø¸ÛŒÙ…Ø§Øª
cp .env.example .env

# ÙˆÛŒØ±Ø§ÛŒØ´ ØªÙ†Ø¸ÛŒÙ…Ø§Øª (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
nano .env

# Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø¨Ø§ Docker Compose
docker compose up -d

# Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ù„Ø§Ú¯â€ŒÙ‡Ø§
docker compose logs -f
```

### Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù¾Ù†Ù„ Ù…Ø¯ÛŒØ±ÛŒØª

Ù¾Ø³ Ø§Ø² Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù…ÙˆÙÙ‚:

- **Ù¾Ù†Ù„ Ù…Ø¯ÛŒØ±ÛŒØª**: http://localhost:3004/admin
- **API**: http://localhost:3004/api
- **Ù†Ø§Ù… Ú©Ø§Ø±Ø¨Ø±ÛŒ**: admin
- **Ø±Ù…Ø² Ø¹Ø¨ÙˆØ±**: admin123 (Ù‚Ø§Ø¨Ù„ ØªØºÛŒÛŒØ± Ø¯Ø± .env)

## Ù¾ÛŒØ´â€ŒÙ†ÛŒØ§Ø²Ù‡Ø§ (Ù†ØµØ¨ Ø¯Ø³ØªÛŒ)

- Node.js 20 ÛŒØ§ Ø¨Ø§Ù„Ø§ØªØ±
- npm ÛŒØ§ yarn
- Chromium Browser
- SQLite3

## Ù†ØµØ¨ Ø±ÙˆÛŒ Ø³Ø±ÙˆØ±

1. Ú©Ù„ÙˆÙ† Ú©Ø±Ø¯Ù† Ù…Ø®Ø²Ù†:
```bash
git clone [repository-url]
cd farsnews
```

2. Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ù†ØµØ¨:
```bash
chmod +x install-server.sh
./install-server.sh
```

3. ÙˆÛŒØ±Ø§ÛŒØ´ ÙØ§ÛŒÙ„ `.env`:
```bash
nano .env
```
ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.

## Ù…Ø¯ÛŒØ±ÛŒØª Ø¨Ø±Ù†Ø§Ù…Ù‡

- Ù…Ø´Ø§Ù‡Ø¯Ù‡ ÙˆØ¶Ø¹ÛŒØª:
```bash
pm2 status
```

- Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ù„Ø§Ú¯â€ŒÙ‡Ø§:
```bash
pm2 logs farsnews-crawler
```

- Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù…Ø¬Ø¯Ø¯:
```bash
pm2 restart farsnews-crawler
```

- ØªÙˆÙ‚Ù:
```bash
pm2 stop farsnews-crawler
```

## Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù¾Ù†Ù„ Ø§Ø¯Ù…ÛŒÙ†

Ù¾Ù†Ù„ Ø§Ø¯Ù…ÛŒÙ† Ø¯Ø± Ø¢Ø¯Ø±Ø³ Ø²ÛŒØ± Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ø§Ø³Øª:
```
http://[server-ip]:3004/admin
```

Ù†Ø§Ù… Ú©Ø§Ø±Ø¨Ø±ÛŒ Ùˆ Ø±Ù…Ø² Ø¹Ø¨ÙˆØ± Ù¾ÛŒØ´â€ŒÙØ±Ø¶:
- Ù†Ø§Ù… Ú©Ø§Ø±Ø¨Ø±ÛŒ: admin
- Ø±Ù…Ø² Ø¹Ø¨ÙˆØ±: admin123

âš ï¸ Ø­ØªÙ…Ø§Ù‹ Ø¨Ø¹Ø¯ Ø§Ø² Ù†ØµØ¨ØŒ Ø±Ù…Ø² Ø¹Ø¨ÙˆØ± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø±Ø§ ØªØºÛŒÛŒØ± Ø¯Ù‡ÛŒØ¯.

## Ø³Ø§Ø®ØªØ§Ø± Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒâ€ŒÙ‡Ø§

- `data/`: Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ùˆ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡
- `logs/`: Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡
- `config/`: ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ
- `public/`: ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ§ØªÛŒÚ© Ùˆ Ù¾Ù†Ù„ Ø§Ø¯Ù…ÛŒÙ†

## Ù¾Ø´ØªÛŒØ¨Ø§Ù†â€ŒÚ¯ÛŒØ±ÛŒ

Ø¨Ø±Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†â€ŒÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³:
```bash
cp data/crawler.db data/crawler.db.backup
```

## Ù…Ø´Ú©Ù„Ø§Øª Ø±Ø§ÛŒØ¬

1. Ø®Ø·Ø§ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Chromium:
```bash
sudo chmod -R 755 /usr/bin/chromium-browser
```

2. Ø®Ø·Ø§ÛŒ Ù¾ÙˆØ±Øª:
Ù¾ÙˆØ±Øª 3004 Ø¨Ø§ÛŒØ¯ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ø¨Ø§Ø´Ø¯. Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ù¾ÙˆØ±Øª Ø±Ø§ Ø¯Ø± ÙØ§ÛŒÙ„ `.env` ØªØºÛŒÛŒØ± Ø¯Ù‡ÛŒØ¯.

## Ø§Ù…Ù†ÛŒØª

- Ø­ØªÙ…Ø§Ù‹ Ø±Ù…Ø² Ø¹Ø¨ÙˆØ± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø±Ø§ ØªØºÛŒÛŒØ± Ø¯Ù‡ÛŒØ¯
- Ø§Ø² ÙØ§ÛŒØ±ÙˆØ§Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯
- Ø¯Ø³ØªØ±Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ ÙØ§ÛŒÙ„ Ø±Ø§ Ù…Ø­Ø¯ÙˆØ¯ Ú©Ù†ÛŒØ¯
- Ø§Ø² HTTPS Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯

## Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ

Ø¨Ø±Ø§ÛŒ Ú¯Ø²Ø§Ø±Ø´ Ù…Ø´Ú©Ù„Ø§Øª ÛŒØ§ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ØŒ Ù„Ø·ÙØ§Ù‹ Issue Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù†ÛŒØ¯.